<h1 align=center>Классификация данных</h1>

## Определение
`Классификация` — это крупнейшая задача Машинного обучения (ML), которая ставит своей целью назначить метку класса Наблюдениям (Observation) из предметной области, например, сортировка электронных писем на "спам" и "не спам".

`Классифицировать объект` — значит, указать номер (или наименование класса), к которому относится данный объект.

`Классификация объекта` — номер или наименование класса, выдаваемый алгоритмом классификации в результате его применения к данному конкретному объекту.

В математической статистике задачи классификации называются также *задачами дискриминантного анализа*.

В машинном обучении задача классификации относится к разделу ***обучения с учителем***. Существует также обучение **без учителя**, когда разделение объектов обучающей выборки на классы не задаётся, и требуется *классифицировать объекты только на основе их сходства друг с другом*. В этом случае принято говорить о задачах кластеризации или таксономии, и классы называть, соответственно, ***кластерами*** или ***таксонами***.

## Задачи

Задача, в которой имеется множество объектов (ситуаций), разделённых, некоторым образом, на классы. Задано конечное множество объектов, для которых известно, к каким классам они относятся. Это множество называется выборкой. Классовая принадлежность остальных объектов неизвестна. Требуется построить алгоритм, способный классифицировать (см. ниже) произвольный объект из исходного множества.

* предсказание категории объекта;
* разделение объектов согласно определенным и заданным заранее признакам. 
    
То есть машина сортирует данные по нужным категориям: одежду – по цветам, сезонам или ткани, книги – по жанрам, авторам, языкам написания, соусы – по степени остроты, письма – по личной или рабочей направленности, спам-составляющей и т.д.

# Типы классификации

<details>
  <summary>

  ### Бинарная классификация (Binary Classification)

  </summary>

  Двоичная классификация предполагает два возможных класса меток. Примеры:

  * Обнаружение спама в электронной почте (спам или нет)
  * Прогнозирование оттока (отток или нет)
  * Прогноз конверсии (купит или нет)
  * Обычно такие задачи включают один класс, который является нормальным состоянием, и другой, который является ненормальным.

  Например, «не спам» – это `нормальное состояние`, а «спам» – `ненормальное состояние`. Другой пример: «рак не обнаружен» – это нормальное состояние задачи медицинской диагностики, а «рак обнаружен» – это ненормальное состояние. Классу для нормального состояния присваивается метка `0`, а классу с ненормальным состоянием – `1`.

  ## Алгоритмы для двоичной классификации

  * Логистическая регрессия (Logistic Regression)
  * Метод K-ближайших соседей (k-Nearest Neighbours)
  * Дерево решений (Decision Tree)
  * Метод опорных векторов (SVM)
  * Наивный байесовский классификатор (Naive Bayes)

  Некоторые алгоритмы специально разработаны для двоичной классификации и изначально не поддерживают более двух классов (это `логистическая регрессия` и `метод опорных векторов`).
</details>


<details>
  <summary>

  ### Мультиклассовая классификация (Multi-Class Classification)

  </summary>
  Мультиклассовая классификация предполагает, что классов более двух. Примеры включают:

  * Классификация лиц
  * Классификация видов растений
  * Оптическое распознавание символов

  В отличие от бинарной классификации, мультиклассовая классификация не имеет понятия нормальных и аномальных исходов. Вместо этого примеры классифицируются как принадлежащие к одному из ряда известных классов.

  Для некоторых задач количество меток классов может быть очень большим. Например, модель может предсказать фотографию как принадлежащую одному из тысяч или десятков тысяч лиц в системе распознавания лиц.

  Обычно такую задачу отрабатывают с помощью модели, которая прогнозирует `Распределение вероятностей Мультинулли (Multinoulli Probability Distribution)` для каждого примера.

  Распределение Мультинулли – это дискретное распределение вероятностей, которое охватывает случай, когда событие будет иметь категориальный исход, например K в {1, 2, 3,…, K}. Для классификации это означает, что модель предсказывает вероятность принадлежности примера к той или иной метке класса.

  Многие алгоритмы, используемые для двоичной классификации, могут использоваться и для мультиклассовой:

  * Метод k-ближайших соседей
  * Дерево решени
  * Наивный байесовский классификатор
  * Случайный лес (Random Forest)
  * Градиентный бустинг (Gradient Boosting)

  Такая классификация использует бинарную для каждого класса по сравнению со всеми другими (`one-vs-rest`) или одного для каждой пары классов (`one-vs-one`):

  * `"Один против остальных" (one-vs-rest)`: создаем одну модель бинарной классификации для каждого класса по сравнению со всеми другими классами
  * `"Один против одного" (one-vs-one)`: создаем одну модель бинарной классификации для каждой пары классов

  Алгоритмы мультиклассовой классификации:

  * Логистическая регрессия
  * Машина опорных векторов
</details>


<details>
<summary>

### Классификация по нескольким меткам (Multi-Label Classification)

</summary>

</details>


<details>
<summary>

### Несбалансированная классификация (Imbalanced Classification)

</summary>

</details>


# Литература

1. https://evergreens.com.ua/ru/articles/classical-machine-learning.html
2. https://habr.com/ru/post/448892/
3. https://biconsult.ru/products/algoritmy-binarnoy-klassifikacii-v-mashinnom-obuchenii
4. https://www.helenkapatsa.ru/klassifikatsiia/
5. https://ru.wikipedia.org/wiki/%D0%94%D0%B2%D0%BE%D0%B8%D1%87%D0%BD%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F#
6. https://tproger.ru/translations/scikit-learn-in-python/
7. https://habr.com/ru/company/skbkontur/blog/553618/
8. https://vc.ru/ml/353279-sposoby-obespecheniya-kachestva-dannyh-dlya-mashinnogo-obucheniya
