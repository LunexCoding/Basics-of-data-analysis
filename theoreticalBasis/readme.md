<h1 align=center>Классификация данных</h1>

## Определение

В контексте машинного обучения классификация относится к обучению с учителем. Такой тип обучения подразумевает, что данные, подаваемые на входы системы, уже помечены, а важная часть признаков уже разделена на отдельные категории или классы. Поэтому сеть уже знает, какая часть входов важна, а какую часть можно самостоятельно проверить. Пример классификации — сортировка различных растений на группы, например «папоротники» и «покрытосеменные».

`Классифицировать объект` — значит, указать номер (или наименование класса), к которому относится данный объект.

`Классификация объекта` — номер или наименование класса, выдаваемый алгоритмом классификации в результате его применения к данному конкретному объекту.

В математической статистике задачи классификации называются также *задачами дискриминантного анализа*.

В машинном обучении задача классификации относится к разделу ***обучения с учителем***. Существует также обучение **без учителя**, когда разделение объектов обучающей выборки на классы не задаётся, и требуется *классифицировать объекты только на основе их сходства друг с другом*. В этом случае принято говорить о задачах кластеризации или таксономии, и классы называть, соответственно, ***кластерами*** или ***таксонами***.

## Задачи

Задача, в которой имеется множество объектов (ситуаций), разделённых, некоторым образом, на классы. Задано конечное множество объектов, для которых известно, к каким классам они относятся. Это множество называется выборкой. Классовая принадлежность остальных объектов неизвестна. Требуется построить алгоритм, способный классифицировать (см. ниже) произвольный объект из исходного множества.

* предсказание категории объекта;
* разделение объектов согласно определенным и заданным заранее признакам. 
    
То есть машина сортирует данные по нужным категориям: одежду – по цветам, сезонам или ткани, книги – по жанрам, авторам, языкам написания, соусы – по степени остроты, письма – по личной или рабочей направленности, спам-составляющей и т.д.


# Типы классификации

<details>
  <summary>

  ### Бинарная классификация (Binary Classification)

  </summary>

  Двоичная классификация предполагает два возможных класса меток. Примеры:

  * Обнаружение спама в электронной почте (спам или нет)
  * Прогнозирование оттока (отток или нет)
  * Прогноз конверсии (купит или нет)
  * Обычно такие задачи включают один класс, который является нормальным состоянием, и другой, который является ненормальным.

  Например, «не спам» – это `нормальное состояние`, а «спам» – `ненормальное состояние`. Другой пример: «рак не обнаружен» – это нормальное состояние задачи медицинской диагностики, а «рак обнаружен» – это ненормальное состояние. Классу для нормального состояния присваивается метка `0`, а классу с ненормальным состоянием – `1`.

  ## Алгоритмы для двоичной классификации

  * Логистическая регрессия (Logistic Regression)
  * Метод K-ближайших соседей (k-Nearest Neighbours)
  * Дерево решений (Decision Tree)
  * Метод опорных векторов (SVM)
  * Наивный байесовский классификатор (Naive Bayes)

  Некоторые алгоритмы специально разработаны для двоичной классификации и изначально не поддерживают более двух классов (это `логистическая регрессия` и `метод опорных векторов`).
</details>


<details>
  <summary>

  ### Мультиклассовая классификация (Multi-Class Classification)

  </summary>
  Мультиклассовая классификация предполагает, что классов более двух. Примеры включают:

  * Классификация лиц
  * Классификация видов растений
  * Оптическое распознавание символов

  В отличие от бинарной классификации, мультиклассовая классификация не имеет понятия нормальных и аномальных исходов. Вместо этого примеры классифицируются как принадлежащие к одному из ряда известных классов.

  Для некоторых задач количество меток классов может быть очень большим. Например, модель может предсказать фотографию как принадлежащую одному из тысяч или десятков тысяч лиц в системе распознавания лиц.

  Обычно такую задачу отрабатывают с помощью модели, которая прогнозирует `Распределение вероятностей Мультинулли (Multinoulli Probability Distribution)` для каждого примера.

  Распределение Мультинулли – это дискретное распределение вероятностей, которое охватывает случай, когда событие будет иметь категориальный исход, например K в {1, 2, 3,…, K}. Для классификации это означает, что модель предсказывает вероятность принадлежности примера к той или иной метке класса.

  Многие алгоритмы, используемые для двоичной классификации, могут использоваться и для мультиклассовой:

  * Метод k-ближайших соседей
  * Дерево решени
  * Наивный байесовский классификатор
  * Случайный лес (Random Forest)
  * Градиентный бустинг (Gradient Boosting)

  Такая классификация использует бинарную для каждого класса по сравнению со всеми другими (`one-vs-rest`) или одного для каждой пары классов (`one-vs-one`):

  * `"Один против остальных" (one-vs-rest)`: создаем одну модель бинарной классификации для каждого класса по сравнению со всеми другими классами
  * `"Один против одного" (one-vs-one)`: создаем одну модель бинарной классификации для каждой пары классов

  Алгоритмы мультиклассовой классификации:

  * Логистическая регрессия
  * Машина опорных векторов
</details>


<details>
  <summary>

  ### Классификация по нескольким меткам (Multi-Label Classification)

  </summary>
  Такая классификация предполагает, что имеется две или более метки классов.

  Рассмотрим пример классификации объектов на фотографии, причем изображение может иметь несколько объектов, таких как «велосипед», «яблоко», «человек» и т.д. Это не похоже на двоичную и мультиклассовую классификации, где для каждого примера прогнозируется одна метка класса.

  По сути, это модель, которая делает несколько прогнозов двоичной классификации для каждого примера.

  Алгоритмы классификации, используемые для двоичной или мультиклассовой классификации, не могут использоваться напрямую для классификации по нескольким меткам. Могут использоваться специализированные версии стандартных алгоритмов:

  * Деревья решений с несколькими ярлыками
  * Случайные леса с несколькими ярлыками
  * Градиентный бустинг с несколькими ярлыками
</details>


<details>
  <summary>

  ### Несбалансированная классификация (Imbalanced Classification)

  </summary>
  Несбалансированная классификация относится к задачам классификации, в которых количество примеров в классах распределяется неравномерно.

  Как правило, такие задачи представляют собой задачи двоичной классификации, где большинство примеров в наборе обучающих данных относятся к нормальному классу, а меньшая часть примеров относится к ненормальному классу.

  Примеры:

  * Обнаружение мошеннических операций (Fraud Detection)
  * Обнаружение выбросов
  * Медицинские диагностические тесты

  Эти проблемы моделируются как задачи бинарной классификации, хотя могут потребоваться специальные методы.

  Примеры алгоритмов:

  * Случайное недосэмплирование (Random Undersampling)
  * Алгоритм SMOTE (SMOTE Oversampling)

  Могут использоваться специализированные алгоритмы моделирования, которые уделяют больше внимания классу меньшинства при подгонке модели к набору обучающих данных, например, Чувствительные к стоимости алгоритмы (Cost-Sensitive Algorithm).

  Примеры:

  * Логистическая регрессия с учетом затрат
  * Деревья принятия решений с учетом затрат
  * Чувствительные к стоимости машины опорных векторов
</details>

# Требования к данным

1. **Релевантность (relevancy)** — набор данных должен содержать только те признаки, которые предоставляют модели значимую информацию. Выявление важных признаков — сложная задача, требующая знания области и чёткого понимания того, какие признаки стоит учитывать, а какие нужно устранить.

2. **Постоянство (consistency)** — схожие примеры должны иметь схожие метки, обеспечивая однородность набора данных.

3. **Однородность (uniformity)** — значения всех атрибутов должны быть сравнимыми для всех данных. Неравномерности или наличие выбросов в наборах данных отрицательно влияют на качество данных обучения.

4. **Полнота (comprehensiveness)** — набор данных должен содержать достаточное количество параметров или признаков, чтобы не осталось неохваченных пограничных случаев. Набор данных должен содержать достаточно сэмплов этих пограничных случаев, чтобы модель могла обучиться и им.

## Очистка данных

Это процесс исправления или удаления неправильных, повреждённых, дублированных данных в пределах набора данных. Этапы процесса очистки данных зависят от конкретного набора данных.

1. Дубликаты - необходимо удалить, поскольку они могут привести модель к переобучению на некоторые паттерны и созданию ложных прогнозов.

2. Выбросы - некоторые части данных ведут себя не так, как остальные данные. Примером может служить SessionID, постоянно встречающийся в данных weblog. Это может происходить из-за каких-то злонамеренных действий, которые не нужно передавать нашей модели.

3. Структурные ошибки - в некоторых случаях в наборе данных может быть ошибочная разметка. Например, `Cat` и `cat` считаются различными классами, а `caat` и `cat` различаются из-за опечатки, приводящей к ошибочному распределению классов.

4. Отсутствующие значения — в наборе данных могут быть элементы, для примеров данных которых отсутствуют атрибуты/признаки.


# Типы классификаторов

<details>
  <summary>

  ### Метод k-ближайших соседей (K-Nearest Neighbors)


  </summary>

  Этот метод работает с помощью поиска кратчайшей дистанции между тестируемым объектом и ближайшими к нему классифицированным объектами из обучающего набора. Классифицируемый объект будет относится к тому классу, к которому принадлежит ближайший объект набора.

  ![](https://media.tproger.ru/uploads/2019/05/overview-classification-methods-python-scikit-learn-4-670x605.png)

</details>


<details>
  <summary>

  ### Классификатор дерева решений (Decision Tree Classifier)

  </summary>

  ![](https://i.vas3k.ru/7rd.jpg)

  Этот классификатор разбивает данные на всё меньшие и меньшие подмножества на основе разных критериев, т. е. у каждого подмножества своя сортирующая категория. С каждым разделением количество объектов определённого критерия уменьшается.

  Классификация подойдёт к концу, когда сеть дойдёт до подмножества только с одним объектом. Если объединить несколько подобных деревьев решений, то получится так называемый `Случайный Лес (Random Forest)`.

  В задаче классификации принимается решение голосованием по большинству.

</details>


<details>
  <summary>

  ### Наивный байесовский классификатор (Naive Bayes)

  </summary>

  ![](https://i.vas3k.ru/7ru.jpg)

  Такой классификатор вычисляет вероятность принадлежности объекта к какому-то классу. Эта вероятность вычисляется из шанса, что какое-то событие произойдёт, с опорой на уже на произошедшие события.

  Каждый параметр классифицируемого объекта считается независимым от других параметров.

</details>


<details>
  <summary>

  ### Линейный дискриминантный анализ (Linear Discriminant Analysis)

  </summary>

  Этот метод работает путём уменьшения размерности набора данных, проецируя все точки данных на линию. Потом он комбинирует эти точки в классы, базируясь на их расстоянии от центральной точки.

  Этот метод, как можно уже догадаться, относится к линейным алгоритмам классификации, т. е. он хорошо подходит для данных с линейной зависимостью.

</details>


<details>
  <summary>

  ### Метод опорных векторов (Support Vector Machines)

  </summary>

  ![](https://i.vas3k.ru/7rh.jpg)

  Работа метода опорных векторов заключается в рисовании линии между разными кластерами точек, которые нужно сгруппировать в классы. С одной стороны линии будут точки, принадлежащие одному классу, с другой стороны — к другому классу.

  Классификатор будет пытаться увеличить расстояние между рисуемыми линиями и точками на разных сторонах, чтобы увеличить свою «уверенность» определения класса. Когда все точки построены, сторона, на которую они падают — это класс, которому эти точки принадлежат.

  ![](https://media.tproger.ru/uploads/2019/05/overview-classification-methods-python-scikit-learn-5-1-670x427.jpg)

</details>


<details>
  <summary>

  ### Логистическая регрессия (Logistic Regression)

  </summary>

  ![](https://i.vas3k.ru/7qy.jpg) 

  ![](https://i.vas3k.ru/7rg.jpg)

  Логистическая регрессия выводит прогнозы о точках в бинарном масштабе — нулевом или единичном. Если значение чего-либо равно либо больше 0.5, то объект классифицируется в большую сторону (к единице). Если значение меньше 0.5 — в меньшую (к нулю).

  У каждого признака есть своя метка, равная только 0 или только 1. Логистическая регрессия является линейным классификатором и поэтому используется, когда в данных прослеживается какая-то линейная зависимость.

</details>


# Оценки качества классификации


## Матрица ошибок (англ. Сonfusion matrix)

Перед переходом к самим метрикам необходимо ввести важную концепцию для описания этих метрик в терминах ***ошибок классификации — confusion matrix (матрица ошибок)***. Допустим, что у нас есть два класса `y={0,1}` и алгоритм, предсказывающий принадлежность каждого объекта одному из классов. 

Любой реальный классификатор совершает ошибки. В нашем случае таких ошибок может быть две:

* Ошибка I рода, или ложно-положительный исход классификации, имеет место, когда отрицательное наблюдение распознано моделью как положительное. 

* Ошибкой II рода, или ложно-отрицательным исходом классификации, называют случай, когда положительное наблюдение распознано как отрицательное. Поясним это с помощью матрицы ошибок классификации:

|      |  y=1                                       | y=0                                      |
| :--: |                    :---:                   |                   :----:                 |
|a(x)=1|	Истинно-положительный (True Positive — TP)|	Ложно-положительный (False Positive — FP)|
|a(x)=0|	Ложно-отрицательный (False Negative — FN) |Истинно-отрицательный (True Negative — TN)|

Здесь `a(x)` — это ответ алгоритма на объекте, а `y` — истинная метка класса на этом объекте.

Таким образом, ошибки классификации бывают двух видов: 

* False Negative (FN)
* False Positive (FP).

`P` означает что классификатор определяет класс объекта как положительный (`N` — отрицательный).

`T` значит что класс предсказан правильно (соответственно `F` — неправильно).

Каждая строка в матрице ошибок представляет спрогнозированный класс, а каждый столбец — фактический класс.


<details>
  <summary>

  ## Доля правильных ответов (Accuracy)

  </summary>

  Интуитивно понятной, очевидной и почти неиспользуемой метрикой является ***accuracy*** — доля правильных ответов алгоритма:

  $accuracy = \frac{TP + TN}{TP+TN+FP+FN}$

  Эта метрика бесполезна в задачах с неравными классами, что как вариант можно исправить с помощью алгоритмов сэмплирования и это легко показать на примере.

  Допустим, мы хотим оценить работу спам-фильтра почты. 

  У нас есть `100` не-спам писем, `90` из которых наш классификатор определил верно (True Negative = 90, False Positive = 10), и `10` спам-писем, `5` из которых классификатор также определил верно (True Positive = 5, False Negative = 5). Тогда accuracy:

  $accuracy = \frac{5+90}{5+90+10+5} = 86,4$

  Однако если мы просто будем предсказывать все письма как не-спам, то получим более высокую аккуратность:

  $accuracy = \frac{0+100}{0+100+0+10} = 90,9$

  При этом, наша модель совершенно не обладает никакой предсказательной силой, так как изначально мы хотели определять письма со спамом.
</details>


<details>
  <summary>

  ## Точность (Precision), Полнота (recall)
  
  </summary>

  Для оценки качества работы алгоритма на каждом из классов по отдельности вводят метрики:

  $precision = \frac{TP}{TP + FP}$

  $recall = \frac{TP}{TP + FN}$


  `Precision` можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а `recall` показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм.

  ![](https://hsto.org/r/w1560/web/38e/9d4/892/38e9d4892d9241ea95e1f56e3ef9124c.png)

  Именно введение `precision` не позволяет нам записывать все объекты в один класс, так как в этом случае мы получаем рост уровня `False Positive`. 
  
  `Recall` демонстрирует способность алгоритма обнаруживать данный класс вообще, а `precision` — способность отличать этот класс от других классов.

</details>

# Кодирование данных

Многие алгоритмы машинного обучения ожидают числовые входные данные, поэтому нам нужно выяснить способ представления наших категориальных данных численным образом.

Одним из решений этого было бы произвольное присвоение числового значения для каждой категории и отображение набора данных из исходных категорий в каждое соответствующее число. 

Выделяют два основных методах:

<details>
  <summary>

  ## Label-Encoder (кодирование меткой)

  </summary>

Этот подход очень прост и включает преобразование каждого значения в столбце в число. Рассмотрим набор данных, в котором описываются категориальные признаки мостов:

| тип моста |
|   :---:   |
|   Arch    |
|   Beam    |
|   Truss   |
|Cantilever |
| Tied Arch |
|Suspension |
|   Cable   |


Теперь закодируем текстовые значения. Позиция текстового значения в наборе данных будет являться его числовым значением.

| тип моста (Текст) | Тип моста (Численное значение)|
| :--------------:  | :---------------------------: |
|   Arch            |           0                   |
|   Beam            |           1                   |
|   Truss           |           2                   |
|Cantilever         |           3                   |
| Tied Arch         |           4                   |
|Suspension         |           5                   |
|   Cable           |           6                   |

На этом мы завершили кодирование метки переменной типа «Мост». Это все, что касается Label-Encoder. Но в зависимости от значений данных и типа данных кодирование меток создает новую проблему, так как использует последовательность чисел. 

Проблема использования такого метода состоит в том, что они вводят сравнение между ними. Нет никакой связи между различными типами мостов, но, глядя на эти числа, можно подумать, что тип моста `Cable` имеет более высокий приоритет над типом моста `Arch`. Алгоритм может неправильно понимать, что данные имеют какой-то порядок `0 <1 <2… <6` и могут придать `Cable` в 6 раз больший вес, чем типу моста `Arch`. 

Теперь рассмотрим другую таблицу, в которой содержится закодированная методом `Label-Encoder` еще один набор данных, описывающей уровень безопасности мостов.


| Уровень безопасности (Текст) | Уровень безопасности (Численное значение)|
| :--------------:  | :---------------------------: |
|   Никакой         |           0                   |
|   Низкий          |           1                   |
|   Средний         |           2                   |
|  Высокий          |           3                   |
|Очень Высокий      |           4                   |

Кодирование `Label-Encoder` в этом столбце также вызывает приоритет по числу, но правильным способом. Здесь числовой порядок не выглядит нестандартным, и будет иметь смысл, если алгоритм интерпретирует порядок безопасности `0 <1 <2 <3 <4`, т. е. `никакой <низкий <средний <высокий <очень высокий`

</details>


<details>
  <summary>

  ## One-Hot-Encoding (Одна горячая кодировка)

  </summary>

  Хотя `Label-Encoder` является прямолинейным, но у него есть недостаток, заключающийся в том, что числовые значения могут быть неверно истолкованы алгоритмами как имеющие некоторый порядок. 
  
  Эта проблема упорядочения решается с помощью другого распространенного альтернативного подхода, называемого `One-Hot-Encoding`. В этом алгоритме каждое значение категории преобразуется в новый столбец, и столбцу присваивается значение `1` или `0`. Давайте рассмотрим предыдущий пример типов мостов и уровней безопасности с `One-Hot-Encoding`.

  | тип моста| Arch | Beam | Truss | Cantilever | Tied Arch | Suspension | Cable |
  |   :---:  | :--: | :--: | :---: | :--------: | :-------: | :--------: | :--:  |
  |   Arch   |   1  |   0  |   0   |      0     |     0     |      0     |   0   |
  |   Beam   |   0  |   1  |   0   |      0     |     0     |      0     |   0   |
  |   Truss  |   0  |   0  |   1   |      0     |     0     |      0     |   0   |
  |Cantilever|   0  |   0  |   0   |      1     |     0     |      0     |   0   |
  | Tied Arch|   0  |   0  |   0   |      0     |     1     |      0     |   0   |
  |Suspension|   0  |   0  |   0   |      0     |     0     |      1     |   0   |
  |   Cable  |   0  |   0  |   0   |      0     |     0     |      0     |   1   |


  

  | Уровень безопасности | Никакой | Низкий | Средний | Высокий | Очень Высокий |
  | :------------------: | :-----: | :----: | :-----: | :-----: | :-----------: |
  |       Никакой        |   1     |   0    |   0     |      0  |     0         |
  |       Низкий         |   0     |   1    |   0     |      0  |     0         |
  |       Средний        |   0     |   0    |   1     |      0  |     0         |
  |      Высокий         |   0     |   0    |   0     |      1  |     0         |
  |      Очень Высокий   |   0     |   0    |   0     |      0  |     1         |
  
Строки с первым значением столбца `Arch/Никакой` будут иметь значение `1` (указывает на истинное значение), а столбцы других значений будут иметь значение `0` (указывающее на ложное значение). Аналогично для других строк сопоставляется значение со значением столбца.

Хотя этот подход устраняет проблемы порядка, но имеет недостаток в добавлении большего количества столбцов в набор данных. Это может привести к значительному увеличению количества столбцов, если у вас есть много уникальных значений в столбце категории. В приведенном выше примере это было управляемо, но управлять им будет действительно сложно, когда кодирование дает много столбцов.

</details>

# Разделение данных для обучения и тестирования

Выделение тестовой выборки необходимо для понимания того, что мы обучили алгоритм в достаточной степени (не произошло переобучение или недообучение).

***Данные обучения (Training data)*** — не менее 60% данных должно использоваться для обучения.

***Данные тестирования (Test data)*** — этот набор данных используется для тестирования модели после её полного обучения. Он отделяется и от набора обучения, и от набора валидации. После обучения и валидации модель тестируется на наборе тестирования. Данные в наборе тестирования должны выглядеть точно так же, как будут выглядеть реальные данные после развёртывания модели.

***Данные валидации (Validation data)*** — выборка (10-20%) из общего набора данных, используемая для валидации и периодически проверяемая на модели во время обучения. Этот набор данных валидации должен представлять собой репрезентативную выборку из набора данных обучения.


![](https://pythonru.com/wp-content/uploads/2021/03/train_test_val_split.png)

Библиотека `sklearn` предоставляет метод `train_test_split`:

```python
sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)[source]
```

```python
>>> import numpy as np
>>> from sklearn.model_selection import train_test_split
>>> X, y = np.arange(10).reshape((5, 2)), range(5)
>>> X
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7],
       [8, 9]])
>>> list(y)
[0, 1, 2, 3, 4]


>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.33, random_state=42)
...
>>> X_train
array([[4, 5],
       [0, 1],
       [6, 7]])
>>> y_train
[2, 0, 3]
>>> X_test
array([[2, 3],
       [8, 9]])
>>> y_test
[1, 4]


>>> train_test_split(y, shuffle=False)
[[0, 1, 2], [3, 4]]
```

# Инструметы

[HostMath](http://www.hostmath.com/) - редактор формул

# Литература

1. https://evergreens.com.ua/ru/articles/classical-machine-learning.html
2. https://habr.com/ru/post/448892/
3. https://www.helenkapatsa.ru/klassifikatsiia/
4. https://ru.wikipedia.org/wiki/%D0%94%D0%B2%D0%BE%D0%B8%D1%87%D0%BD%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F#
5. https://tproger.ru/translations/scikit-learn-in-python/
6. https://vc.ru/ml/353279-sposoby-obespecheniya-kachestva-dannyh-dlya-mashinnogo-obucheniya
7. https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0_%D0%B2_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0%D1%85_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8_%D0%B8_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8
8. http://blog.datalytica.ru/2018/04/blog-post.html
9. https://moluch.ru/archive/311/70393/